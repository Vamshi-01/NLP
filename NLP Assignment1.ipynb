{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but aren’t sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning.**"
      ],
      "metadata": {
        "id": "vMacopTg_s8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Split the above paragraph to SENTENCES"
      ],
      "metadata": {
        "id": "5EEfl0dOAAmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLcCQOzkAJpj",
        "outputId": "6aa5681d-4529-40aa-9963-a6ca80a5d94c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but aren’t sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning.\"\n",
        "tokenizer=nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
        "sentences=tokenizer.tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu3Fga1GAgOo",
        "outputId": "7cdf3d41-4634-41cf-982c-7b84b8b6857b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Are you fascinated by the amount of text data available on the internet?', 'Are you looking for ways to work with this text data but aren’t sure where to begin?', 'Machines, after all, recognize numbers, not the letters of our language.', 'And that can be a tricky landscape to navigate in machine learning.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but aren’t sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning.**"
      ],
      "metadata": {
        "id": "T9rF6DCuA8vL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Split the above paragraph into WORDS"
      ],
      "metadata": {
        "id": "Ep0l46HvA-id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but aren’t sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning.\"\n",
        "words=nltk.tokenize.word_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7OwflyNBBiS",
        "outputId": "628e949a-bb42-4bf1-bd65-34e4635861ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Are', 'you', 'fascinated', 'by', 'the', 'amount', 'of', 'text', 'data', 'available', 'on', 'the', 'internet', '?', 'Are', 'you', 'looking', 'for', 'ways', 'to', 'work', 'with', 'this', 'text', 'data', 'but', 'aren', '’', 't', 'sure', 'where', 'to', 'begin', '?', 'Machines', ',', 'after', 'all', ',', 'recognize', 'numbers', ',', 'not', 'the', 'letters', 'of', 'our', 'language', '.', 'And', 'that', 'can', 'be', 'a', 'tricky', 'landscape', 'to', 'navigate', 'in', 'machine', 'learning', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Find BoW for the given paragraph? And also find stem and lemma words?"
      ],
      "metadata": {
        "id": "KE8OrZ_LBVvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Summarization is one of those applications of Natural Language Processing (NLP) which is bound to have a huge impact on our lives. With growing digital media and ever-growing publishing – who has the time to go through entire articles / documents / books to decide whether they are useful or not? Thankfully – this technology is already here.**"
      ],
      "metadata": {
        "id": "2-g8CV-nBefR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlysiEgMBqi4",
        "outputId": "c1c0c18e-564b-49df-df17-3f775c6dc649"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "text=\"Text Summarization is one of those applications of Natural Language Processing (NLP) which is bound to have a huge impact on our lives. With growing digital media and ever-growing publishing – who has the time to go through entire articles / documents / books to decide whether they are useful or not? Thankfully – this technology is already here.\"\n",
        "stop_words=set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "dZzZ9oUwCRmm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "result=word_tokenize(text)\n",
        "BoW=[]\n",
        "for i in result:\n",
        "  if i not in stop_words:\n",
        "    BoW.append(i)\n",
        "    BoW.append(\" \")\n",
        "\"\".join(BoW)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "xhF-IsZHCZt9",
        "outputId": "d0461cd8-4459-4dda-d322-0daf28d3f48c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Text Summarization one applications Natural Language Processing ( NLP ) bound huge impact lives . With growing digital media ever-growing publishing – time go entire articles / documents / books decide whether useful ? Thankfully – technology already . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9CXanPvCdxe",
        "outputId": "8e4da621-7886-460b-c187-f694ae8e4448"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps=PorterStemmer()\n",
        "text=\"Text Summarization is one of those applications of Natural Language Processing (NLP) which is bound to have a huge impact on our lives. With growing digital media and ever-growing publishing – who has the time to go through entire articles / documents / books to decide whether they are useful or not? Thankfully – this technology is already here.\"\n",
        "words=nltk.tokenize.word_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts2Ia3M5Cirq",
        "outputId": "ac1a7d0d-62cf-4cc9-925f-cff414dd985c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Text', 'Summarization', 'is', 'one', 'of', 'those', 'applications', 'of', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'which', 'is', 'bound', 'to', 'have', 'a', 'huge', 'impact', 'on', 'our', 'lives', '.', 'With', 'growing', 'digital', 'media', 'and', 'ever-growing', 'publishing', '–', 'who', 'has', 'the', 'time', 'to', 'go', 'through', 'entire', 'articles', '/', 'documents', '/', 'books', 'to', 'decide', 'whether', 'they', 'are', 'useful', 'or', 'not', '?', 'Thankfully', '–', 'this', 'technology', 'is', 'already', 'here', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(ps.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bou1sg0MCoOl",
        "outputId": "086b93fb-2ed6-49a2-c705-624c4444c646"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text\n",
            "summar\n",
            "is\n",
            "one\n",
            "of\n",
            "those\n",
            "applic\n",
            "of\n",
            "natur\n",
            "languag\n",
            "process\n",
            "(\n",
            "nlp\n",
            ")\n",
            "which\n",
            "is\n",
            "bound\n",
            "to\n",
            "have\n",
            "a\n",
            "huge\n",
            "impact\n",
            "on\n",
            "our\n",
            "live\n",
            ".\n",
            "with\n",
            "grow\n",
            "digit\n",
            "media\n",
            "and\n",
            "ever-grow\n",
            "publish\n",
            "–\n",
            "who\n",
            "ha\n",
            "the\n",
            "time\n",
            "to\n",
            "go\n",
            "through\n",
            "entir\n",
            "articl\n",
            "/\n",
            "document\n",
            "/\n",
            "book\n",
            "to\n",
            "decid\n",
            "whether\n",
            "they\n",
            "are\n",
            "use\n",
            "or\n",
            "not\n",
            "?\n",
            "thank\n",
            "–\n",
            "thi\n",
            "technolog\n",
            "is\n",
            "alreadi\n",
            "here\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkji7C3kCtW9",
        "outputId": "40868665-3f1b-436c-ae6c-aaa7daf7223b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm =WordNetLemmatizer()\n",
        "for word in words:\n",
        "  print(lm.lemmatize(word,pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9JST3OTCwqv",
        "outputId": "c911a0ce-ecc8-4381-c003-5d58db54455f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text\n",
            "Summarization\n",
            "be\n",
            "one\n",
            "of\n",
            "those\n",
            "applications\n",
            "of\n",
            "Natural\n",
            "Language\n",
            "Processing\n",
            "(\n",
            "NLP\n",
            ")\n",
            "which\n",
            "be\n",
            "bind\n",
            "to\n",
            "have\n",
            "a\n",
            "huge\n",
            "impact\n",
            "on\n",
            "our\n",
            "live\n",
            ".\n",
            "With\n",
            "grow\n",
            "digital\n",
            "media\n",
            "and\n",
            "ever-growing\n",
            "publish\n",
            "–\n",
            "who\n",
            "have\n",
            "the\n",
            "time\n",
            "to\n",
            "go\n",
            "through\n",
            "entire\n",
            "article\n",
            "/\n",
            "document\n",
            "/\n",
            "book\n",
            "to\n",
            "decide\n",
            "whether\n",
            "they\n",
            "be\n",
            "useful\n",
            "or\n",
            "not\n",
            "?\n",
            "Thankfully\n",
            "–\n",
            "this\n",
            "technology\n",
            "be\n",
            "already\n",
            "here\n",
            ".\n"
          ]
        }
      ]
    }
  ]
}